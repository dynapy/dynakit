{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FE\n",
    "\n",
    "> This module contains functionality for FE simulations and generating dataset for Machine Learnig.This module    hosts all the functions dealing with FE simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pyDOE import lhs\n",
    "import numpy as np\n",
    "from scipy.stats.distributions import norm\n",
    "from scipy.stats import uniform\n",
    "import yaml\n",
    "from qd.cae.dyna import KeyFile\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import subprocess \n",
    "import shlex\n",
    "from diversipy.hycusampling import maximin_reconstruction as maxmin\n",
    "import csv\n",
    "\n",
    "class FE():\n",
    "    \"\"\"\n",
    "    This Class contains set of methods which performs reading of the .yaml file and replaces values of the input parameters \n",
    "    with newly generated sample data sets. And then, new key files are generated for simulation. \n",
    "    \n",
    "    -----------\n",
    "       INPUTS  \n",
    "    -----------\n",
    "            settigs : Input file for FE simulations to get the user input                \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, settings):\n",
    " \n",
    "        self.settings = settings\n",
    "        self.folders_count=0\n",
    "        self._get_user_input()\n",
    "     \n",
    "    def _get_user_input(self): \n",
    "        \"\"\" gets the user input details from the settings.yaml file.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        fin_dir         :   Final path of the created directory\n",
    "        self.Run        :   Number of runs\n",
    "        self.para_list  :   A .yaml file containing the parameters/ features/ variables for sampling with appropriate\n",
    "                            values as subkeys in the same file.\n",
    "        self.key        :   .key file containg the initial simulation details. \n",
    "        \"\"\"\n",
    "\n",
    "        with open(self.settings,'r') as file:\n",
    "            inp = yaml.load(file, Loader=yaml.FullLoader) \n",
    "        inp_vals=[*inp.values()]\n",
    "        inp_keys=[*inp.keys()]\n",
    "        \n",
    "        req=['Newfolder_name','Runs','key','config'] \n",
    "        \n",
    "        for names in req:\n",
    "            if names not in inp_keys:\n",
    "                raise Exception(names +\" not in settings.yaml file\")\n",
    "            if inp[names] == None:\n",
    "                raise Exception(names +\" value not in settings.yaml file\")\n",
    "                \n",
    "        if isinstance(inp['Runs'], int) == True:\n",
    "            self.Run=inp['Runs']\n",
    "            self.int='yes'\n",
    "            self.Flag=1\n",
    "        elif isinstance(inp['Runs'], str) == True:\n",
    "            self.DOE=pd.read_csv(inp['Runs'])\n",
    "            self.int='no'\n",
    "            self.Run=len(self.DOE)\n",
    "            self.Flag=1\n",
    "        else:\n",
    "            print('Enter either a Integer or a .csv Input')\n",
    "            \n",
    "        dir_main=None\n",
    "        if 'Directory' in inp_keys:   \n",
    "            dir_main=inp['Directory']            \n",
    "        file_name=inp['Newfolder_name']\n",
    "        self.key=inp['key']\n",
    "        self.para_list=inp['config']\n",
    "\n",
    "        if dir_main == None:\n",
    "            current_directory = os.getcwd()\n",
    "            self.fin_dir = os.path.join(current_directory,file_name)\n",
    "            self.dyna_dir = os.path.join(self.fin_dir,'.dynakit')\n",
    "        else:      \n",
    "            self.fin_dir = os.path.join(dir_main,file_name)    \n",
    "            self.dyna_dir = os.path.join(self.fin_dir,'.dynakit')\n",
    "        try:\n",
    "            os.mkdir(self.fin_dir)\n",
    "            os.mkdir(self.dyna_dir)\n",
    "        except OSError as err:\n",
    "            print('Adding new samples to the existing directory')\n",
    "            self.Flag=0\n",
    "        self._set_keypath()\n",
    "                \n",
    "        return self.fin_dir , self.Run , self.key , self.para_list\n",
    "                      \n",
    "    def _set_keypath(self):\n",
    "        \"\"\" changes the *INCLUDE PATH card in the key file\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dir_main : path of the directory the other .k files are present\n",
    "        file_name: Name of the newly created file\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self.newkey : a new key file with an updated file path.\n",
    "        \n",
    "        \"\"\"\n",
    "        k = KeyFile(self.key)\n",
    "        include_path = k[\"*INCLUDE_PATH\"][0]\n",
    "        path_s=self.fin_dir\n",
    "        include_path[0] =path_s.replace('\\\\','/')\n",
    "        curr_path=os.getcwd()\n",
    "        os.chdir(self.fin_dir)\n",
    "        k.save(\"upd_key.key\")\n",
    "        os.chdir(curr_path)\n",
    "        self.newkey ='upd_key.key'\n",
    "        \n",
    "        return self.newkey\n",
    "    \n",
    "    def Read_config(self):\n",
    "        \"\"\" converts the .yaml file to a dictionary\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self.para_list : the config.yaml file  with the user inputs\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        z : the .yaml file in dictionary format\n",
    "        \n",
    "        \"\"\"  \n",
    "        with open(self.para_list,'r') as file:\n",
    "            parameter_list  = yaml.load(file, Loader=yaml.FullLoader) \n",
    "        dynParams = {k: v for k, v in parameter_list['parameters'].items() if parameter_list['parameters'][k]['type'] == 'dynaParameter'}\n",
    "        self.dynaParameters = pd.DataFrame.from_dict(dynParams)\n",
    "        \n",
    "        return self.dynaParameters\n",
    "    \n",
    "\n",
    "    def get_samples(self): \n",
    "        \"\"\" samples the data based on the .yaml file using normal distribution and lhs library\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        vars      : values assigned to the sub keys in the .yaml file\n",
    "        self.Run  : Number of samples required \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Data   : samples matrix in a list\n",
    "        \n",
    "        \"\"\" \n",
    "        os.chdir(self.dyna_dir)\n",
    "        if self.int=='yes':\n",
    "            self.col_names=self.dynaParameters.loc['parameter']\n",
    "        elif self.int=='no':\n",
    "            self.col_names=self.DOE.columns\n",
    "\n",
    "        if self.int =='yes':\n",
    "            self.DOE = lhs(len(self.dynaParameters.loc['parameter']),samples = self.Run)\n",
    "            save_file=pd.DataFrame(self.DOE)\n",
    "            os.chdir(self.dyna_dir)\n",
    "            save_file.to_csv('DOE.csv', index=False)\n",
    "            minimum_val = self.dynaParameters.loc['min']\n",
    "            maximum_val = self.dynaParameters.loc['max']\n",
    "            for i in range(0,len(self.dynaParameters.loc['parameter'])):\n",
    "                self.DOE[:,i]=uniform(minimum_val[i], maximum_val[i]-minimum_val[i]).ppf(self.DOE[:, i])\n",
    "                \n",
    "        elif self.int=='no':\n",
    "            os.chdir(self.dyna_dir)\n",
    "            df=self.DOE\n",
    "            df.to_csv('DOE.csv', index=False)\n",
    "            self.DOE=np.array(self.DOE)\n",
    "            \n",
    "        return self.DOE\n",
    "    \n",
    "    def add_samples(self):\n",
    "        os.chdir(self.dyna_dir)\n",
    "        if os.path.isfile('DOE.csv'):\n",
    "            old_DOE=pd.read_csv('DOE.csv')\n",
    "        else:\n",
    "            print('No preexisting DOE found!')\n",
    "        if self.int=='yes':\n",
    "            self.col_names=self.dynaParameters.loc['parameter']\n",
    "        elif self.int=='no':\n",
    "            self.col_names=self.DOE.columns\n",
    "        if self.int=='yes':\n",
    "            data_add = lhs(len(self.dynaParameters.loc['parameter']), samples=self.Run)\n",
    "            self.DOE = maxmin(self.Run,len(self.dynaParameters.loc['parameter']), num_steps=None, initial_points=data_add, existing_points=old_DOE, use_reflection_edge_correction=None, dist_matrix_function=None, callback=None)\n",
    "            df=pd.DataFrame(self.DOE)\n",
    "            os.chdir(self.dyna_dir)\n",
    "            df.to_csv('DOE.csv', mode='a', header=False, index=False)\n",
    "            min_newsample_val = self.dynaParameters.loc['min']\n",
    "            max_newsample_val = self.dynaParameters.loc['max']\n",
    "            for i in range(0,len(self.dynaParameters.loc['parameter'])):\n",
    "                self.DOE[:,i]=uniform(min_newsample_val[i], max_newsample_val[i]-min_newsample_val[i]).ppf(self.DOE[:, i])\n",
    "        elif self.int=='no':\n",
    "            os.chdir(self.dyna_dir)\n",
    "            df=self.DOE\n",
    "            df.to_csv('DOE.csv', mode='a', header=False, index=False)\n",
    "            self.DOE=np.array(self.DOE)\n",
    "\n",
    "        return self.DOE\n",
    "                       \n",
    "    def generate_key_file(self): \n",
    "        \"\"\" Generate the new updated .key file and a FE_Parameters.yaml file containing respective sampled values \n",
    "        for each parameters in new folders.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self.newkey      : a new key file with an updated file path.\n",
    "        fin_dir          : final path of the created directory\n",
    "        self.Run         : Number of samples required \n",
    "        self.para_num    : number of parameters/variables/features\n",
    "        self.para_names  : Names of parameters/variables/features\n",
    "        Data             : samples matrix in a list\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Data   : samples matrix in a list\n",
    "        \n",
    "        \"\"\"\n",
    "        os.chdir(self.fin_dir)\n",
    "        kf=KeyFile(self.newkey)  \n",
    "        key_parameters=kf[\"*PARAMETER\"][0]\n",
    "        key_parameters_array=np.array(kf[\"*PARAMETER\"][0])\n",
    "        \n",
    "        # Creating a dictionary with key and it's values:\n",
    "        key_dict={}\n",
    "        R_index=[]\n",
    "        for i in range(0,len(key_parameters_array)):\n",
    "            if key_parameters_array[i].startswith('R'):\n",
    "                R_index.append(i)\n",
    "                f=key_parameters_array[i].split(' ')\n",
    "                key_dict[f[1]]=f[-1]\n",
    "        par_lis=[*key_dict.keys()]\n",
    "        os.chdir(self.fin_dir)\n",
    "        self.folders_count =len([name for name in os.listdir(os.getcwd()) if name.startswith('Run')])\n",
    "\n",
    "        \n",
    "        for run in range(0,self.Run):\n",
    "            \n",
    "            os.mkdir('Run_'+str(run+self.folders_count+1))\n",
    "            os.chdir('Run_'+str(run+self.folders_count+1))\n",
    "            FE_Parameters = {}\n",
    "            \n",
    "            for para in range(0,len(self.col_names)):\n",
    "                \n",
    "                for i in range(0,len(R_index)):\n",
    "                    \n",
    "                    if par_lis[i] == self.col_names[para]:\n",
    "                        \n",
    "                        key_parameters[i+1,1] = self.DOE[run,para]                 \n",
    "                        kf.save(\"run_main_{}.key\".format(str(run+self.folders_count+1)))\n",
    "                        FE_Parameters[par_lis[i]] =  key_parameters[i+1,1]\n",
    "                    with open('simulation_Parameters.yaml','w') as FE_file:\n",
    "                        yaml.dump(FE_Parameters,FE_file,default_flow_style = False)\n",
    "            os.chdir(self.fin_dir)    \n",
    "              \n",
    "        \n",
    "    def get_simulation_files(self):\n",
    "        \"\"\" \n",
    "        Runs all the methods of pre-process class\n",
    "        \n",
    "        \"\"\"\n",
    "        self.Read_config()\n",
    "        if self.Flag==1:\n",
    "            self.get_samples()\n",
    "        elif self.Flag==0:\n",
    "            self.add_samples()\n",
    "        self.generate_key_file()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=FE('settings.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Test the object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cur=os.getcwd()\n",
    "def test_object(k,path_cur):\n",
    "    os.chdir(path_cur)\n",
    "    assert os.path.exists('Test_file//.dynakit') == True\n",
    "    assert os.path.exists('Test_file') == True\n",
    "    \n",
    "test_object(k,path_cur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Test `Read_config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_Read_config(k):\n",
    "    df=k.Read_config()\n",
    "    with open('config.yaml','r') as file:\n",
    "        para_list  = yaml.load(file, Loader=yaml.FullLoader) \n",
    "    a={k: v for k, v in para_list['parameters'].items() if para_list['parameters'][k]['type'] == 'dynaParameter'}\n",
    "    assert len([*a.keys()])==len(df.columns)\n",
    "    assert len([*a.values()][0])==len(df)\n",
    "    assert [*a.values()][0]['max'] == df.iloc[:,0]['max']\n",
    "    \n",
    "test_Read_config(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test `get_samples`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_samples(k):\n",
    "    df=k.Read_config()\n",
    "    test_array=k.get_samples()\n",
    "    \n",
    "    assert df.iloc[:,0]['min']<min(test_array[:,0])\n",
    "    assert df.iloc[:,0]['max']>max(test_array[:,0])\n",
    "    \n",
    "test_get_samples(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Test `generate_key_file`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_cur)\n",
    "def test_generate_key_file(k):\n",
    "    path=os.path.join(os.getcwd(),'Test_file')\n",
    "    k.Read_config()\n",
    "    test_array=k.get_samples()\n",
    "    k.generate_key_file()\n",
    "    indx=len([name for name in os.listdir(path) if name.startswith('Run')])\n",
    "    \n",
    "    assert len(test_array)==indx\n",
    "    \n",
    "test_generate_key_file(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test `add samples`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_cur)\n",
    "doe_o=len(pd.read_csv(\"Test_file/.dynakit/DOE.csv\"))\n",
    "def test_add_samples(k):\n",
    "    with open('settings.yaml','r') as file:\n",
    "        set_list  = yaml.load(file, Loader=yaml.FullLoader) \n",
    "    k_1=FE('settings.yaml')\n",
    "    k_1.Read_config()\n",
    "    k_1.add_samples()\n",
    "    doe_n=pd.read_csv(\"DOE.csv\")\n",
    "    assert doe_o+set_list['Runs'] == len(doe_n)\n",
    "test_add_samples(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
