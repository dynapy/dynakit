{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp FE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FE\n",
    "\n",
    "> This module contains functions to generate parametric LS-Dyna simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pyDOE import lhs\n",
    "import numpy as np\n",
    "from scipy.stats.distributions import norm\n",
    "from scipy.stats import uniform\n",
    "import yaml\n",
    "from qd.cae.dyna import KeyFile\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import subprocess \n",
    "import shlex\n",
    "from diversipy.hycusampling import maximin_reconstruction as maxmin\n",
    "import csv\n",
    "\n",
    "class FE():\n",
    "    \"\"\"\n",
    "    This Class contains set of methods which performs reading of the .yaml file and replaces values of the input parameters \n",
    "    with newly generated sample data sets. And then, new key files are generated for simulation. \n",
    "    \n",
    "    -----------\n",
    "       INPUTS  \n",
    "    -----------\n",
    "            settigs : Input file for FE simulations to get the user input                \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, settings):\n",
    " \n",
    "        self.settings = settings\n",
    "        self.folders_count=0\n",
    "        self._get_user_input()\n",
    "     \n",
    "    def _get_user_input(self): \n",
    "        \"\"\" gets the user input details from the settings.yaml file.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        fin_dir         :   Final path of the created directory\n",
    "        self.Run        :   Number of runs\n",
    "        self.para_list  :   A .yaml file containing the parameters/ features/ variables for sampling with appropriate\n",
    "                            values as subkeys in the same file.\n",
    "        self.key        :   .key file containg the initial simulation details. \n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\" gets the user input details from the settings.yaml file.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        fin_dir         :   Final path of the created directory\n",
    "        self.Run        :   Number of runs\n",
    "        self.para_list  :   A .yaml file containing the parameters/ features/ variables for sampling with appropriate\n",
    "                            values as subkeys in the same file.\n",
    "        self.key        :   .key file containg the initial simulation details. \n",
    "        \"\"\"\n",
    "\n",
    "        with open(self.settings,'r') as file:\n",
    "            inp = yaml.load(file, Loader=yaml.FullLoader) \n",
    "        inp_vals=[*inp.values()]\n",
    "        inp_keys=[*inp.keys()]\n",
    "        \n",
    "        req=['project_path','simulations','key','FE_parameters'] \n",
    "        \n",
    "        for names in req:\n",
    "            if names not in inp_keys:\n",
    "                raise Exception(names +\" not in settings.yaml file\")\n",
    "            if inp[names] == None:\n",
    "                raise Exception(names +\" value not in settings.yaml file\")\n",
    "                \n",
    "        if isinstance(inp['simulations'], int) == True:\n",
    "            self.Run=inp['simulations']\n",
    "            self.int='yes'\n",
    "            self.Flag=1\n",
    "        elif isinstance(inp['simulations'], str) == True:\n",
    "            self.DOE=pd.read_csv(inp['simulations'])\n",
    "            self.int='no'\n",
    "            self.Run=len(self.DOE)\n",
    "            self.Flag=1\n",
    "        else:\n",
    "            print('Enter either a Integer or a .csv Input')\n",
    "               \n",
    "        self.key=inp['key']\n",
    "        self.fin_dir=inp['project_path']\n",
    "        self.basename=inp['basefile']\n",
    "        self.para_list=inp['FE_parameters']\n",
    "        self.ncpu = inp['NCPU']\n",
    "        self.ls_run_exe = inp['LS_Dyna_executable']\n",
    "        self.outputs=inp['program_name']\n",
    "        self.cwd=os.getcwd()\n",
    "        \n",
    "        self.dyna_dir = os.path.join(self.fin_dir,'.dynakit')\n",
    "        self.basepath=os.path.join(self.fin_dir,self.basename)\n",
    "        self.fol_name=self.basename.split('_')[0]\n",
    "\n",
    "        try:\n",
    "            os.mkdir(self.dyna_dir)\n",
    "        except OSError as err:\n",
    "            print('Adding new samples to the existing directory')\n",
    "            self.Flag=0\n",
    "                \n",
    "        return self.fin_dir , self.Run , self.key , self.para_list\n",
    "   \n",
    "\n",
    "    def Read_config(self):\n",
    "        \"\"\" converts the .yaml file to a dictionary\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self.para_list : the config.yaml file  with the user inputs\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        z : the .yaml file in dictionary format\n",
    "        \n",
    "        \"\"\"  \n",
    "        os.chdir(self.cwd)\n",
    "        with open(self.para_list,'r') as file:\n",
    "            parameter_list  = yaml.load(file, Loader=yaml.FullLoader) \n",
    "        dynParams = {k: v for k, v in parameter_list['parameters'].items() if parameter_list['parameters'][k]['type'] == 'dynaParameter'}\n",
    "        self.dynaParameters = pd.DataFrame.from_dict(dynParams)\n",
    "        \n",
    "        onparams = {k: v for k, v in dynParams.items() if dynParams[k]['status'] == True }\n",
    "        self.new_par=pd.DataFrame.from_dict(onparams)             \n",
    "        on=self.new_par.loc['parameter']\n",
    "        self.on_params=on.to_list()\n",
    "        \n",
    "        return self.dynaParameters\n",
    "    \n",
    "\n",
    "    def get_samples(self): \n",
    "        \"\"\" samples the data based on the .yaml file using normal / uniform  distribution and lhs library\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        vars      : values assigned to the sub keys in the .yaml file\n",
    "        self.Run  : Number of samples required \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Data   : samples matrix in a list\n",
    "        \n",
    "        \"\"\" \n",
    "        os.chdir(self.dyna_dir)\n",
    "        if self.int=='yes':\n",
    "            self.col_names=self.dynaParameters.loc['parameter']\n",
    "        elif self.int=='no':\n",
    "            self.col_names=self.DOE.columns\n",
    "\n",
    "        if self.int =='yes':\n",
    "            \n",
    "            DOE_s = lhs(len(self.new_par.loc['parameter']),samples = self.Run)\n",
    "            j=0\n",
    "            self.DOE=np.zeros((self.Run,len(self.dynaParameters.loc['parameter'])))\n",
    "            for i in range(0,len(self.dynaParameters.loc['parameter'])):\n",
    "                if self.dynaParameters.loc['parameter'][i] in self.on_params:\n",
    "                    self.DOE[:,i]=DOE_s[:,j]\n",
    "                    j+=1\n",
    "                else:\n",
    "                    self.DOE[:,i]=1\n",
    "            \n",
    "            save_file=pd.DataFrame(self.DOE)\n",
    "            os.chdir(self.dyna_dir)\n",
    "            save_file.to_csv('DOE.csv', index=False)\n",
    "            minimum_val = self.dynaParameters.loc['min']\n",
    "            maximum_val = self.dynaParameters.loc['max']\n",
    "            \n",
    "            for j in range(0,len(self.dynaParameters.loc['parameter'])):\n",
    "                if self.dynaParameters.loc['parameter'][j] in self.on_params:\n",
    "                    if self.dynaParameters.loc['distribution'][j]=='Uniform':\n",
    "                        self.DOE[:,j]=uniform(self.dynaParameters.loc['min'][j], self.dynaParameters.loc['max'][j] - self.dynaParameters.loc['min'][j]).ppf(self.DOE[:, j])\n",
    "                    elif self.dynaParameters.loc['distribution'][j]=='Normal':\n",
    "                        self.DOE[:, j] = norm(loc=self.dynaParameters.loc['mean'][j], scale=self.dynaParameters.loc['SD'][j]).ppf(self.DOE[:, j])\n",
    "                else:\n",
    "                    self.DOE[:,j]=self.dynaParameters.loc['default'][j]\n",
    "\n",
    "        elif self.int=='no':\n",
    "            os.chdir(self.dyna_dir)\n",
    "            df=self.DOE\n",
    "            df.to_csv('DOE.csv', index=False)\n",
    "            self.DOE=np.array(self.DOE)\n",
    "            \n",
    "        return self.DOE\n",
    "\n",
    "    def add_samples(self):\n",
    "        \"\"\" adds samples of the data based on the .yaml file using normal / uniform distribution and lhs library\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        vars      : values assigned to the sub keys in the .yaml file\n",
    "        self.Run  : Number of samples required \n",
    "        self.fin_dir     : final path of the created directory\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Data   : samples matrix in a list\n",
    "        \n",
    "        \"\"\" \n",
    "        os.chdir(self.fin_dir)\n",
    "        self.folders_count =len([name for name in os.listdir(os.getcwd()) if name.startswith(self.fol_name)])-1\n",
    "        os.chdir(self.dyna_dir)\n",
    "        \n",
    "        if os.path.isfile('DOE.csv'):\n",
    "            old_DOE_s=pd.read_csv('DOE.csv')\n",
    "        else:\n",
    "            print('No preexisting DOE found!')\n",
    "        \n",
    "        if self.int=='yes':\n",
    "            self.col_names=self.dynaParameters.loc['parameter']\n",
    "        elif self.int=='no':\n",
    "            self.col_names=self.DOE.columns\n",
    "        if self.int=='yes':\n",
    "            old_DOE=np.zeros((self.folders_count,len(self.new_par.loc['parameter'])))\n",
    "            old=old_DOE_s.values\n",
    "            j=0\n",
    "            for i in range(0,len(self.dynaParameters.loc['parameter'])):\n",
    "                if self.dynaParameters.loc['parameter'][i] in self.on_params:\n",
    "                    old_DOE[:,j]=old[:,i]\n",
    "                    j+=1\n",
    "            data_add=lhs(len(self.new_par.loc['parameter']),samples = self.Run)\n",
    "            DOE_new_add= maxmin(self.Run,len(self.new_par.loc['parameter']), num_steps=None, initial_points=data_add, existing_points=old_DOE, use_reflection_edge_correction=None, dist_matrix_function=None, callback=None)\n",
    "\n",
    "            new_DOE=np.zeros((self.Run,len(self.dynaParameters.loc['parameter'])))\n",
    "            j=0\n",
    "            for i in range(0,len(self.dynaParameters.loc['parameter'])):\n",
    "                if self.dynaParameters.loc['parameter'][i] in self.on_params:\n",
    "                    new_DOE[:,i]=DOE_new_add[:,j]\n",
    "                    j+=1\n",
    "                else:\n",
    "                    new_DOE[:,i]=1\n",
    "            df=pd.DataFrame(new_DOE)    \n",
    "           \n",
    "            os.chdir(self.dyna_dir)\n",
    "            df.to_csv('DOE.csv', mode='a', header=False, index=False)\n",
    "            \n",
    "            self.DOE= pd.read_csv('DOE.csv')\n",
    "        \n",
    "            for j in range(0,len(self.dynaParameters.loc['parameter'])):\n",
    "                if self.dynaParameters.loc['parameter'][j] in self.on_params:\n",
    "                    if self.dynaParameters.loc['distribution'][j]=='Uniform':\n",
    "                        self.DOE.values[:,j]=uniform(self.dynaParameters.loc['min'][j], self.dynaParameters.loc['max'][j] - self.dynaParameters.loc['min'][j]).ppf(self.DOE.values[:, j])\n",
    "                    elif self.dynaParameters.loc['distribution'][j]=='Normal':\n",
    "                        self.DOE.values[:, j] = norm(loc=self.dynaParameters.loc['mean'][j], scale=self.dynaParameters.loc['SD'][j]).ppf(self.DOE.values[:, j])\n",
    "                else:\n",
    "                    self.DOE.values[:,j]=self.dynaParameters.loc['default'][j]\n",
    "                    \n",
    "            self.DOE=self.DOE.values\n",
    "            \n",
    "        elif self.int=='no':\n",
    "            os.chdir(self.dyna_dir)\n",
    "            df=self.DOE\n",
    "            df.to_csv('DOE.csv', mode='a', header=False, index=False)\n",
    "            self.DOE=np.array(self.DOE)\n",
    "\n",
    "        return self.DOE\n",
    "    \n",
    "    def generate_key_file(self): \n",
    "        \"\"\" Generate the new updated .key file and a FE_Parameters.yaml file containing respective sampled values \n",
    "        for each parameters in new folders.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self.newkey      : a new key file with an updated file path.\n",
    "        self.fin_dir     : final path of the created directory\n",
    "        self.Run         : Number of samples required \n",
    "        self.para_num    : number of parameters/variables/features\n",
    "        self.para_names  : Names of parameters/variables/features\n",
    "        self.DOE         : samples matrix in a list\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        fldolder in the directory\n",
    "        \n",
    "        \"\"\"\n",
    "        os.chdir(self.basepath)\n",
    "        kf=KeyFile(self.key)\n",
    "        os.chdir(self.fin_dir)  \n",
    "        key_parameters=kf[\"*PARAMETER\"][0]\n",
    "        key_parameters_array=np.array(kf[\"*PARAMETER\"][0])\n",
    "        \n",
    "        # Creating a dictionary with key and it's values:\n",
    "        key_dict={}\n",
    "        R_index=[]\n",
    "        for i in range(0,len(key_parameters_array)):\n",
    "            if key_parameters_array[i].startswith('R'):\n",
    "                R_index.append(i)\n",
    "                f=key_parameters_array[i].split(' ')\n",
    "                key_dict[f[1]]=f[-1]\n",
    "        par_lis=[*key_dict.keys()]\n",
    "        os.chdir(self.fin_dir)\n",
    "        self.folders_count =len([name for name in os.listdir(os.getcwd()) if name.startswith(self.fol_name)])\n",
    "\n",
    "        \n",
    "        for run in range(0,self.Run):\n",
    "            \n",
    "            os.mkdir('{}_{:03}'.format(self.fol_name,(run+self.folders_count)))\n",
    "            os.chdir('{}_{:03}'.format(self.fol_name,(run+self.folders_count)))\n",
    "            FE_Parameters = {}\n",
    "            \n",
    "            for para in range(0,len(self.col_names)):\n",
    "                \n",
    "                for i in range(0,len(R_index)):\n",
    "                    \n",
    "                    if par_lis[i] == self.col_names[para]:\n",
    "                        \n",
    "                        key_parameters[i+1,1] = self.DOE[run+self.folders_count-1,para]                 \n",
    "                        kf.save(\"run_main_{:03}.key\".format((run+self.folders_count)))\n",
    "                        FE_Parameters[par_lis[i]] =  key_parameters[i+1,1]\n",
    "                    with open('simulation_Parameters.yaml','w') as FE_file:\n",
    "                        yaml.dump(FE_Parameters,FE_file,default_flow_style = False)\n",
    "            os.chdir(self.fin_dir)        \n",
    "        \n",
    "    def get_simulation_files(self):\n",
    "        \"\"\" \n",
    "        Runs all the methods of pre-process class\n",
    "        \n",
    "        \"\"\"\n",
    "        self.Read_config()\n",
    "        if self.Flag==1:\n",
    "            self.get_samples()\n",
    "        elif self.Flag==0:\n",
    "            self.add_samples()\n",
    "        self.generate_key_file()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ls_Run method\n",
    "add the functionality to execute lsDyna using subprocess\n",
    "\n",
    "### Post process\n",
    "generalised script to combine the results extracted by the"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cur_path=os.getcwd()\n",
    "path=os.path.join(cur_path,'example')\n",
    "pro_path=os.path.join(path,'test_project')\n",
    "base_path=os.path.join(path,'main')\n",
    "os.chdir(path)\n",
    "with open('dynakit_FE.yaml') as file:\n",
    "    a  = yaml.load(file, Loader=yaml.FullLoader) \n",
    "a['project_path']=pro_path\n",
    "name=a['basefile']\n",
    "with open('dynakit_FE.yaml','w') as file:\n",
    "    yaml.dump(a,file) \n",
    "\n",
    "file_name=name.split('_')[0]\n",
    "k=FE('dynakit_FE.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Test the object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_cur=os.getcwd()\n",
    "def test_object(k,pro_path):\n",
    "    os.chdir(pro_path)\n",
    "    assert os.path.exists('.dynakit') == True\n",
    "#     assert os.path.exists('Test_file') == True\n",
    "    \n",
    "test_object(k,pro_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Test `Read_config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_Read_config(k,path):\n",
    "    df=k.Read_config()\n",
    "    os.chdir(path)\n",
    "    with open('FE_parameters.yaml','r') as file:\n",
    "        para_list  = yaml.load(file, Loader=yaml.FullLoader) \n",
    "    a={k: v for k, v in para_list['parameters'].items() if para_list['parameters'][k]['type'] == 'dynaParameter'}\n",
    "    assert len([*a.keys()])==len(df.columns)\n",
    "    assert len([*a.values()][0])==len(df)\n",
    "    assert [*a.values()][0]['max'] == df.iloc[:,0]['max']\n",
    "    \n",
    "test_Read_config(k,path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test `get_samples`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_samples(k):\n",
    "    df=k.Read_config()\n",
    "    test_array=k.get_samples()\n",
    "    \n",
    "    assert df.iloc[:,0]['min']<min(test_array[:,0])\n",
    "    assert df.iloc[:,0]['max']>max(test_array[:,0])\n",
    "    \n",
    "test_get_samples(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Test `generate_key_file`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(pro_path)\n",
    "def test_generate_key_file(k):\n",
    "#     path=os.path.join(os.getcwd(),file_name)\n",
    "    k.Read_config()\n",
    "    test_array=k.get_samples()\n",
    "    k.generate_key_file()\n",
    "    indx=len([name for name in os.listdir(pro_path) if name.startswith(file_name)])-1\n",
    "    \n",
    "    assert len(test_array)==indx\n",
    "    \n",
    "test_generate_key_file(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test `add samples`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(pro_path)\n",
    "doe_o=len(pd.read_csv(\".dynakit/DOE.csv\"))\n",
    "os.chdir(path)\n",
    "def test_add_samples(k):\n",
    "    with open('dynakit_FE.yaml','r') as file:\n",
    "        set_list  = yaml.load(file, Loader=yaml.FullLoader) \n",
    "    k_1=FE('dynakit_FE.yaml')\n",
    "    k_1.Read_config()\n",
    "    k_1.add_samples()\n",
    "    doe_n=pd.read_csv(\"DOE.csv\")\n",
    "    assert doe_o+set_list['simulations'] == len(doe_n)\n",
    "test_add_samples(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
