{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp FE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FE\n",
    "\n",
    "> This module contains functions to generate parametric LS-Dyna simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pyDOE import lhs\n",
    "import numpy as np\n",
    "from scipy.stats.distributions import norm\n",
    "from scipy.stats import uniform\n",
    "import yaml\n",
    "from shutil import *\n",
    "import os\n",
    "import pandas as pd\n",
    "from diversipy.hycusampling import maximin_reconstruction as maxmin\n",
    "from pathlib import PurePath\n",
    "\n",
    "class FE():\n",
    "    \"\"\"\n",
    "    This Class contains set of methods which performs reading of the .yaml file and replaces values of the input parameters \n",
    "    with newly generated sample data sets. And then, new key files are generated for simulation. \n",
    "    \n",
    "    -----------\n",
    "       INPUTS  \n",
    "    -----------\n",
    "            settigs : Input file for FE simulations to get the user input                \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, settings):\n",
    " \n",
    "        self.settings = settings\n",
    "        self.folders_count=0\n",
    "        self._read_user_input()\n",
    "     \n",
    "    def _read_user_input(self): \n",
    "        \"\"\" gets the user input details from the settings.yaml file.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        fin_dir         :   Final path of the created directory\n",
    "        self.Run        :   Number of runs\n",
    "        self.para_list  :   A .yaml file containing the parameters/ features/ variables for sampling with appropriate\n",
    "                            values as subkeys in the same file.\n",
    "        self.key        :   .key file containg the initial simulation details. \n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\" gets the user input details from the settings.yaml file.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        fin_dir         :   Final path of the created directory\n",
    "        self.Run        :   Number of runs\n",
    "        self.para_list  :   A .yaml file containing the parameters/ features/ variables for sampling with appropriate\n",
    "                            values as subkeys in the same file.\n",
    "        self.key        :   .key file containg the initial simulation details. \n",
    "        \"\"\"\n",
    "\n",
    "        with open(self.settings,'r') as file:\n",
    "            inp = yaml.load(file, Loader=yaml.FullLoader) \n",
    "        inp_vals=[*inp.values()]\n",
    "        inp_keys=[*inp.keys()]\n",
    "        \n",
    "        req=['baseline_directory','simulations'] \n",
    "        \n",
    "        for names in req:\n",
    "            if names not in inp_keys:\n",
    "                raise Exception(names +\" not in dynakit_FE.yaml file\")\n",
    "            if inp[names] == None:\n",
    "                raise Exception(names +\" value not in dynakit_FE.yaml file\")\n",
    "                \n",
    "        if isinstance(inp['simulations'], int) == True:\n",
    "            self.Run=inp['simulations']\n",
    "            self.int='yes'\n",
    "            self.Flag=1\n",
    "        elif isinstance(inp['simulations'], str) == True:\n",
    "            self.DOE=pd.read_csv(inp['simulations'])\n",
    "            self.int='no'\n",
    "            self.Run=len(self.DOE)\n",
    "            self.Flag=1\n",
    "        else:\n",
    "            print('Enter either a Integer or a .csv Input')\n",
    "            \n",
    "        self.cwd=os.getcwd()\n",
    "        \n",
    "        base_dir=PurePath(inp['baseline_directory'])\n",
    "        self.basepath=os.path.abspath(base_dir)\n",
    "        self.fin_dir=os.path.dirname(self.basepath)\n",
    "         \n",
    "\n",
    "        self.basename=base_dir.name\n",
    "        self.dyna_dir = os.path.join(self.fin_dir,'.dynakit')\n",
    "        self.para_list='FE_parameters.yaml'\n",
    "        \n",
    "\n",
    "        self.mainkey=inp['main_key']\n",
    "        self.pkey=inp['parameters']\n",
    "        \n",
    "        \n",
    "        self.fol_name=self.basename.split('_')[0]\n",
    "        \n",
    "        if os.path.exists(self.dyna_dir):\n",
    "            if [name for name in os.listdir(self.dyna_dir) if name.endswith(\".csv\")] == []:\n",
    "                os.rmdir(self.dyna_dir)\n",
    "\n",
    "        try:\n",
    "            os.mkdir(self.dyna_dir)\n",
    "        except OSError as err:\n",
    "            print('Adding new samples to the existing directory')\n",
    "            self.Flag=0\n",
    "                \n",
    "        return self.fin_dir , self.Run , self.pkey , self.para_list\n",
    "   \n",
    "\n",
    "    def read_parameters(self):\n",
    "        \"\"\" converts the .yaml file to a dictionary\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self.para_list : the config.yaml file  with the user inputs\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        z : the .yaml file in dictionary format\n",
    "        \n",
    "        \"\"\"  \n",
    "        os.chdir(self.fin_dir)\n",
    "        with open(self.para_list,'r') as file:\n",
    "            parameter_list  = yaml.load(file, Loader=yaml.FullLoader) \n",
    "        dynParams = {k: v for k, v in parameter_list['parameters'].items() if parameter_list['parameters'][k]['type'] == 'dynaParameter'}\n",
    "        self.dynaParameters = pd.DataFrame.from_dict(dynParams)\n",
    "        \n",
    "        onparams = {k: v for k, v in dynParams.items() if dynParams[k]['status'] == True }\n",
    "        self.new_par=pd.DataFrame.from_dict(onparams)             \n",
    "        on=self.new_par.loc['parameter']\n",
    "        self.on_params=on.to_list()\n",
    "        \n",
    "        return self.dynaParameters\n",
    "    \n",
    "\n",
    "    def get_samples(self): \n",
    "        \"\"\" samples the data based on the .yaml file using normal / uniform  distribution and lhs library\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        vars      : values assigned to the sub keys in the .yaml file\n",
    "        self.Run  : Number of samples required \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Data   : samples matrix in a list\n",
    "        \n",
    "        \"\"\" \n",
    "        os.chdir(self.dyna_dir)\n",
    "        if self.int=='yes':\n",
    "            self.col_names=self.dynaParameters.loc['parameter']\n",
    "        elif self.int=='no':\n",
    "            self.col_names=self.DOE.columns\n",
    "\n",
    "        if self.int =='yes':\n",
    "            \n",
    "            DOE_s = lhs(len(self.new_par.loc['parameter']),samples = self.Run)\n",
    "            j=0\n",
    "            self.DOE=np.zeros((self.Run,len(self.dynaParameters.loc['parameter'])))\n",
    "            for i in range(0,len(self.dynaParameters.loc['parameter'])):\n",
    "                if self.dynaParameters.loc['parameter'][i] in self.on_params:\n",
    "                    self.DOE[:,i]=DOE_s[:,j]\n",
    "                    j+=1\n",
    "                else:\n",
    "                    self.DOE[:,i]=1\n",
    "            \n",
    "            save_file=pd.DataFrame(self.DOE)\n",
    "            os.chdir(self.dyna_dir)\n",
    "            save_file.to_csv('DOE.csv', index=False)\n",
    "            minimum_val = self.dynaParameters.loc['min']\n",
    "            maximum_val = self.dynaParameters.loc['max']\n",
    "            \n",
    "            for j in range(0,len(self.dynaParameters.loc['parameter'])):\n",
    "                if self.dynaParameters.loc['parameter'][j] in self.on_params:\n",
    "                    if self.dynaParameters.loc['distribution'][j]=='Uniform':\n",
    "                        self.DOE[:,j]=uniform(self.dynaParameters.loc['min'][j], self.dynaParameters.loc['max'][j] - self.dynaParameters.loc['min'][j]).ppf(self.DOE[:, j])\n",
    "                    elif self.dynaParameters.loc['distribution'][j]=='Normal':\n",
    "                        self.DOE[:, j] = norm(loc=self.dynaParameters.loc['mean'][j], scale=self.dynaParameters.loc['SD'][j]).ppf(self.DOE[:, j])\n",
    "                else:\n",
    "                    self.DOE[:,j]=self.dynaParameters.loc['default'][j]\n",
    "\n",
    "        elif self.int=='no':\n",
    "            os.chdir(self.dyna_dir)\n",
    "            df=self.DOE\n",
    "            df.to_csv('DOE.csv', index=False)\n",
    "            self.DOE=np.array(self.DOE)\n",
    "            \n",
    "        return self.DOE\n",
    "\n",
    "    def add_samples(self):\n",
    "        \"\"\" adds samples of the data based on the .yaml file using normal / uniform distribution and lhs library\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        vars      : values assigned to the sub keys in the .yaml file\n",
    "        self.Run  : Number of samples required \n",
    "        self.fin_dir     : final path of the created directory\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Data   : samples matrix in a list\n",
    "        \n",
    "        \"\"\" \n",
    "        os.chdir(self.cwd)\n",
    "        os.chdir(self.fin_dir)\n",
    "        self.folders_count =len([name for name in os.listdir(os.getcwd()) if name.startswith(self.fol_name)])-1\n",
    "        os.chdir(self.dyna_dir)\n",
    "        \n",
    "        if os.path.isfile('DOE.csv'):\n",
    "            old_DOE_s=pd.read_csv('DOE.csv')\n",
    "        else:\n",
    "            print('No preexisting DOE found!')\n",
    "        \n",
    "        if self.int=='yes':\n",
    "            self.col_names=self.dynaParameters.loc['parameter']\n",
    "        elif self.int=='no':\n",
    "            self.col_names=self.DOE.columns\n",
    "        if self.int=='yes':\n",
    "            old_DOE=np.zeros((self.folders_count,len(self.new_par.loc['parameter'])))\n",
    "            old=old_DOE_s.values\n",
    "            j=0\n",
    "            for i in range(0,len(self.dynaParameters.loc['parameter'])):\n",
    "                if self.dynaParameters.loc['parameter'][i] in self.on_params:\n",
    "                    old_DOE[:,j]=old[:,i]\n",
    "                    j+=1\n",
    "            data_add=lhs(len(self.new_par.loc['parameter']),samples = self.Run)\n",
    "            DOE_new_add= maxmin(self.Run,len(self.new_par.loc['parameter']), num_steps=None, initial_points=data_add, existing_points=old_DOE, use_reflection_edge_correction=None, dist_matrix_function=None, callback=None)\n",
    "\n",
    "            new_DOE=np.zeros((self.Run,len(self.dynaParameters.loc['parameter'])))\n",
    "            j=0\n",
    "            for i in range(0,len(self.dynaParameters.loc['parameter'])):\n",
    "                if self.dynaParameters.loc['parameter'][i] in self.on_params:\n",
    "                    new_DOE[:,i]=DOE_new_add[:,j]\n",
    "                    j+=1\n",
    "                else:\n",
    "                    new_DOE[:,i]=1\n",
    "            df=pd.DataFrame(new_DOE)    \n",
    "           \n",
    "            os.chdir(self.dyna_dir)\n",
    "            df.to_csv('DOE.csv', mode='a', header=False, index=False)\n",
    "            \n",
    "            self.DOE= pd.read_csv('DOE.csv')\n",
    "        \n",
    "            for j in range(0,len(self.dynaParameters.loc['parameter'])):\n",
    "                if self.dynaParameters.loc['parameter'][j] in self.on_params:\n",
    "                    if self.dynaParameters.loc['distribution'][j]=='Uniform':\n",
    "                        self.DOE.values[:,j]=uniform(self.dynaParameters.loc['min'][j], self.dynaParameters.loc['max'][j] - self.dynaParameters.loc['min'][j]).ppf(self.DOE.values[:, j])\n",
    "                    elif self.dynaParameters.loc['distribution'][j]=='Normal':\n",
    "                        self.DOE.values[:, j] = norm(loc=self.dynaParameters.loc['mean'][j], scale=self.dynaParameters.loc['SD'][j]).ppf(self.DOE.values[:, j])\n",
    "                else:\n",
    "                    self.DOE.values[:,j]=self.dynaParameters.loc['default'][j]\n",
    "                    \n",
    "            self.DOE=self.DOE.values\n",
    "            \n",
    "        elif self.int=='no':\n",
    "            os.chdir(self.dyna_dir)\n",
    "            df=self.DOE\n",
    "            df.to_csv('DOE.csv', mode='a', header=False, index=False)\n",
    "            self.DOE=np.array(self.DOE)\n",
    "\n",
    "        return self.DOE\n",
    "    \n",
    "    def generate_keyfile(self):\n",
    "        os.chdir(self.fin_dir)         \n",
    "        self.folders_count =len([name for name in os.listdir(os.getcwd()) if name.startswith(self.fol_name)])\n",
    "\n",
    "        for run in range(0,self.Run):\n",
    "            os.chdir(self.basepath)\n",
    "            keyfile=pd.read_table(self.pkey,index_col=None)\n",
    "            os.chdir(self.fin_dir)\n",
    "            os.mkdir('{}_{:03}'.format(self.fol_name,(run+self.folders_count)))\n",
    "            os.chdir(os.path.join(self.fin_dir,'{}_{:03}'.format(self.fol_name,(run+self.folders_count))))\n",
    "            \n",
    "            FE_Parameters = {}\n",
    "            for para in range(0,len(self.col_names)):\n",
    "                for k,v in enumerate(keyfile.values):\n",
    "                    if v[0].startswith((\"R\")):\n",
    "                        if v[0].strip(\"\\n\").split()[1] == self.col_names[para]:\n",
    "                            v[0]=v[0].replace(str(v[0].strip(\"\\n\").split()[2]),str(self.DOE[run+self.folders_count-1,para]))\n",
    "                            FE_Parameters[str(v[0].strip(\"\\n\").split()[1])] =  str(v[0].strip(\"\\n\").split()[2])\n",
    "            keyfile.to_csv(\"parameters.key\".format((run+self.folders_count)), index=None)\n",
    "            with open('simulation_Parameters.yaml','w') as FE_file:\n",
    "                yaml.dump(FE_Parameters,FE_file,default_flow_style = False)\n",
    "            \n",
    "        for numbs in range(0,self.Run):\n",
    "            for filename in os.listdir(self.basepath):\n",
    "                if not filename == self.pkey:\n",
    "                    os.chdir(self.basepath)\n",
    "                    copy(filename, os.path.join(self.fin_dir,'{}_{:03}'.format(self.fol_name,(numbs+self.folders_count))))\n",
    "\n",
    "  \n",
    "    def get_simulation_files(self):\n",
    "        \"\"\" \n",
    "        Runs all the methods of pre-process class\n",
    "        \n",
    "        \"\"\"\n",
    "        self.read_parameters()\n",
    "        if self.Flag==1:\n",
    "            self.get_samples()\n",
    "        elif self.Flag==0:\n",
    "            self.add_samples()\n",
    "        self.generate_keyfile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the library to run the program.\n",
    "To access the Dynakit library, the user need to fill necessary key inputs in dynakit_FE.yaml and FE_parameters.yaml files\n",
    "\n",
    "- User input in dynakit_FE.yaml\n",
    "\n",
    "```yaml\n",
    "# Path to baseline input file\n",
    "\n",
    "baseline_directory : 'example\\test_project\\base_000'\n",
    "\n",
    "# If a number is given, the DoE is generated for the given number\n",
    "# If you prefer to provide the DoE, input the DoE as a csv and give its name here \n",
    "\n",
    "simulations: 5\n",
    "\n",
    "``` \n",
    "\n",
    "- Inputs to the FE_parameters.yaml file are given as below,\n",
    "\n",
    "```yaml\n",
    "parameters:\n",
    "  'delta velocity' :\n",
    "        type :  dynaParameter\n",
    "        status: off\n",
    "        parameter : DV\n",
    "        default : 60\n",
    "        max  : 65\n",
    "        min : 40\n",
    "        distribution: Uniform/Normal\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import os\n",
    "path_to_run=os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case, dynakit_FE.yaml will read from the working directory:\n",
    "\n",
    "project =FE(\"example/test_project/dynakit_FE.yaml\") \n",
    "\n",
    "\n",
    "# if dynakit_FE.yaml will be in a different directory:\n",
    "\n",
    "# project = FE(r'D:\\Project_1\\dynakit_FE.yaml') \n",
    "\n",
    "# reads FE_parameters.yaml file and creates dictionary for the parameters with type 'dynaparameters'\n",
    "df=project.read_parameters()\n",
    "\n",
    "#samples the data for the given parameter ranges and type of distribution specified by the user.\n",
    "df_DOE=project.get_samples()\n",
    "\n",
    "# Generates the key files based on the sampled data for each parameters\n",
    "project.generate_keyfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "os.chdir(path_to_run)\n",
    "with open('example/test_project/dynakit_FE.yaml','r') as file:\n",
    "        dyna  = yaml.load(file, Loader=yaml.FullLoader) \n",
    "\n",
    "project_path=os.path.dirname(os.path.abspath(dyna['baseline_directory']))\n",
    "\n",
    "file_name=[name for name in os.listdir(project_path) if not (name.startswith('.'))][0].split('_')[0]\n",
    "\n",
    "# --------------------test 1-----------------------------------------------\n",
    "os.chdir(project_path)\n",
    "assert os.path.exists('.dynakit') == True\n",
    "\n",
    "# -------------------test for config----------------------------------------\n",
    "os.chdir(path_to_run)\n",
    "with open('example/test_project/FE_parameters.yaml','r') as file:\n",
    "        para_list  = yaml.load(file, Loader=yaml.FullLoader) \n",
    "a={k: v for k, v in para_list['parameters'].items() if para_list['parameters'][k]['type'] == 'dynaParameter'}\n",
    "\n",
    "assert len([*a.keys()])==len(df.columns)\n",
    "assert len([*a.values()][0])==len(df)\n",
    "assert [*a.values()][0]['max'] == df.iloc[:,0]['max']\n",
    "\n",
    "# -------------------------Test for get_samples ------------------------------\n",
    "assert df.iloc[:,0]['min']<min(df_DOE[:,0])\n",
    "assert df.iloc[:,0]['max']>max(df_DOE[:,0])\n",
    "\n",
    "# -----------------------test for the generate_keyfile-------------------------\n",
    "\n",
    "# assert dyna['simulations'] == (len([name for name in os.listdir(project_path) if name.startswith(file_name)])-1)\n",
    "\n",
    "# save the length of the DOE to compare later\n",
    "os.chdir(project_path)\n",
    "doe_o=len(pd.read_csv(\".dynakit/DOE.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation\n",
    "- Adding more samples to the existing sample set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "os.chdir(path_to_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initiate the program for augmenting\n",
    "project = FE('example/test_project/dynakit_FE.yaml') \n",
    "\n",
    "df=project.read_parameters()\n",
    "\n",
    "# augmentation method for sampling \n",
    "df_DOE=project.add_samples()\n",
    "\n",
    "# to generate key files\n",
    "project.generate_keyfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#--------------------------test for augmentation---------------------------\n",
    "\n",
    "os.chdir(path_to_run)\n",
    "with open('example/test_project/dynakit_FE.yaml','r') as file:\n",
    "    set_list  = yaml.load(file, Loader=yaml.FullLoader) \n",
    "    \n",
    "os.chdir(project_path)\n",
    "doe_n=pd.read_csv(\".dynakit/DOE.csv\")\n",
    "\n",
    "assert doe_o+set_list['simulations'] == len(doe_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all methods:\n",
    "- Run the complete program in a single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "os.chdir(path_to_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the program for augmenting\n",
    "project = FE('example/test_project/dynakit_FE.yaml') \n",
    "\n",
    "# command to execute all the methods\n",
    "project.get_simulation_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('dynakit_env')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
